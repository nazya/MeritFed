{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea397aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nazya/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from attrs import define\n",
    "from codes.train import train\n",
    "# from codes.train_dist import train\n",
    "from codes.optimizers.base import Optimizer\n",
    "# from code.problems import Problem\n",
    "from codes import Loss\n",
    "from codes.datasets import Dataset\n",
    "from codes.models import Model\n",
    "\n",
    "# %matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b5d8cd-078e-4292-97c9-0c7a02c57fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zip_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    for instance in zip(*kwargs.values()):\n",
    "        yield dict(zip(keys, instance))\n",
    "\n",
    "\n",
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    for instance in itertools.product(*kwargs.values()):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb69728-dca1-4d11-a498-69874930542c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MKL_THREADING_LAYER\"] = \"AMD\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"TORCH_DEVICE\"] = \"cuda\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d681b5-96b4-41e2-86af-563b88775df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_VERBOSE'] = 'True'\n",
    "os.environ['MLFLOW_CHECK_EXIST'] = 'True'\n",
    "os.environ['MLFLOW_EXPERIMENT_NAME'] = os.path.basename(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563a0e6-5394-4956-ac72-fef9058294cf",
   "metadata": {},
   "source": [
    "# 3 classes emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279ed62f-ca45-4fa5-9391-85be3895f436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@define\n",
    "class BaseConfig():\n",
    "    nepochs:         int = 40\n",
    "    # niters:          int = 2500\n",
    "    npeers:          int = 20\n",
    "    seed:            int = 0\n",
    "\n",
    "    loss:           Loss = Loss.CrossEntropyLoss\n",
    "    model:         Model = Model.BERT\n",
    "    dataset:     Dataset = Dataset.GoEmotions\n",
    "\n",
    "    # nsamples:        int = 1000\n",
    "    valenabled_:    bool = False\n",
    "    valnsamples_:    int = None\n",
    "    nclasses:        int = 28\n",
    "    hratio:        float = None\n",
    "\n",
    "    optimizer: Optimizer = None\n",
    "    batchsize:       int = 40\n",
    "    lr:            float = 1e-2\n",
    "\n",
    "    trueweights:    bool = None\n",
    "\n",
    "    mdbatchsize_:    int = 30\n",
    "    mdniters_:       int = None\n",
    "    mdlr_:           int = None\n",
    "    mdfull_:        bool = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9465e9ec-6150-40f7-af5f-bfbf63d313ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 536 ms, total: 2.11 s\n",
      "Wall time: 2.11 s\n",
      "CPU times: user 1.51 s, sys: 688 ms, total: 2.2 s\n",
      "Wall time: 2.2 s\n",
      "CPU times: user 1.85 s, sys: 600 ms, total: 2.45 s\n",
      "Wall time: 2.46 s\n",
      "CPU times: user 1.7 s, sys: 612 ms, total: 2.31 s\n",
      "Wall time: 2.32 s\n",
      "CPU times: user 1.77 s, sys: 708 ms, total: 2.48 s\n",
      "Wall time: 2.48 s\n",
      "CPU times: user 1.53 s, sys: 711 ms, total: 2.24 s\n",
      "Wall time: 2.25 s\n",
      "CPU times: user 1.83 s, sys: 848 ms, total: 2.68 s\n",
      "Wall time: 2.72 s\n",
      "CPU times: user 1.61 s, sys: 648 ms, total: 2.26 s\n",
      "Wall time: 2.57 s\n",
      "CPU times: user 2.02 s, sys: 955 ms, total: 2.98 s\n",
      "Wall time: 3.15 s\n",
      "CPU times: user 1.69 s, sys: 671 ms, total: 2.36 s\n",
      "Wall time: 2.98 s\n",
      "trueweights=[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Step 1000: train-loss: 0.00780 train-accuracy: 99.80000 test-loss: 1.59432 test-accuracy: 72.80100\n",
      "CPU times: user 30min 19s, sys: 49min 28s, total: 1h 19min 48s\n",
      "Wall time: 1h 19min 55s\n",
      "trueweights=[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: train-loss: 0.01725 train-accuracy: 99.70000 test-loss: 1.21586 test-accuracy: 73.923891\n",
      "CPU times: user 32min 34s, sys: 50min 13s, total: 1h 22min 47s\n",
      "Wall time: 1h 22min 38s\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_RUN_TAGS'] = str(dict(about=f'{BaseConfig().valenabled_=} / {BaseConfig().nclasses} / single thread'))\n",
    "\n",
    "args_grid = dict(\n",
    "    # hratio=[0.99, 0.9, 0.7, 0.5],\n",
    "    hratio=[0.9],\n",
    "    mdlr_=[0.1],\n",
    "    seed=[0,1,2],\n",
    "    # valenabled=[True, False]\n",
    "    valenabled_=[False]\n",
    ")\n",
    "\n",
    "for d in product_dict(**args_grid):\n",
    "\n",
    "    os.environ['MLFLOW_RUN_NAME'] = 'SGD Full'\n",
    "    config = BaseConfig(**d)\n",
    "    config.mdlr_ = None\n",
    "    config.mdbatchsize_ = None\n",
    "    config.optimizer = Optimizer.SGD\n",
    "    config.trueweights = False\n",
    "    # %time train(config)\n",
    "    %time train(config)\n",
    "\n",
    "    os.environ['MLFLOW_RUN_NAME'] = 'SGD Ideal'\n",
    "    config = BaseConfig(**d)\n",
    "    config.mdlr_ = None\n",
    "    config.mdbatchsize_ = None\n",
    "    config.hratio = None\n",
    "    config.optimizer = Optimizer.SGD\n",
    "    config.trueweights = True\n",
    "    %time train(config)\n",
    "\n",
    "    # os.environ['MLFLOW_RUN_NAME'] = 'MeritFed MD'\n",
    "    # config = BaseConfig(**d)\n",
    "    # config.optimizer = Optimizer.MeritFed\n",
    "    # config.mdfull_ = True\n",
    "    # config.mdniters_ = 1\n",
    "    # # config.md_lr_ = 0.05\n",
    "    # %time train(config)\n",
    "\n",
    "    # os.environ['MLFLOW_RUN_NAME'] = 'MeritFed SMD'\n",
    "    # config = BaseConfig(**d)\n",
    "    # config.optimizer = Optimizer.MeritFed\n",
    "    # config.mdfull_ = False\n",
    "    # config.mdniters_ = 10\n",
    "    # # config.md_lr_ = 0.05\n",
    "    # %time train(config)\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = Optimizer.TAWT\n",
    "    os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    config.mdlr_ = None\n",
    "    %time train(config)\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = Optimizer.FedAdp\n",
    "    os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    config.mdlr_ = None\n",
    "    %time train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "vscode": {
   "interpreter": {
    "hash": "18f7a5ae47153a9b42c5447ccb1bbe68959e117ab7750209e163c7c253c9e013"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
